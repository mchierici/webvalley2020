{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJfNUgelLKKI"
   },
   "source": [
    "# <center>Machine learning from scratch - Part I</center>\n",
    "## <center>WebValley ReImagined 2020</center>\n",
    "### <center>Marco Chierici</center>\n",
    "#### <center>FBK/MPBA</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fuVtNnbq1o3z"
   },
   "source": [
    "In this handout we will go through basic concepts of machine learning using Python and scikit-learn, first on the classic Iris dataset, then on a real-world dataset of biological relevance (Zhang et al, _Genome Biology_ , 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris dataset starter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This initial section is meant as a starter to have a first glimpse at machine learning examples taking advantage of the Iris dataset. \n",
    "\n",
    "First, load required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Python numerical library\n",
    "import pandas as pd # data structures tools\n",
    "from sklearn import datasets # small datasets as a playground for machine learning\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **sklearn.datasets** package includes some small datasets that can be used for practice. One of them is the Iris Fischer dataset, introduced quickly in the first lecture. \n",
    "\n",
    "We can load the dataset using the datasets loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets loader returns a dictionary-like object called <i>bunch</i> holding at least two items: an <i>array</i> of shape n_samples * n_features with key <b>data</b> and a <i>numpy array</i> of length n_samples, containing the target values, with key <b>target</b>.\n",
    "\n",
    "Let's have a first look at the data. Just type `iris`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the Iris dataset, the _data_ array (`iris.data` or equivalently `iris['data']`) contains 150 samples and 4 features. These dimensions can be accessed with the shape attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent\n",
    "iris['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more intuitive way of dealing with datasets of this type are **pandas dataframes**. In the code below, we convert the Iris dataset to a pandas dataframe and visualize its first five rows using the function **head()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "iris_df['species'] = iris['target']\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _species_ columns is the target variable (the class labels) and is coded as\n",
    "* 0 = Iris setosa;\n",
    "* 1 = Iris versicolor;\n",
    "* 2 = Iris virginica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to actually look at the data, plotting sepal length vs petal length for the full Iris dataset. We'll use three different colors to represent the three species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, define the colors for plotting and the species names in two separate lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ['red', 'orange', 'blue']\n",
    "species = ['I. setosa', 'I. versicolor', 'I. virginica']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then plot. I am plotting one species at a time (that's why I am looping through `i`).\n",
    "\n",
    "Speaking about `for` loops, here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's loop over the species list and print its elements\n",
    "\n",
    "for i in [0, 1, 2]:\n",
    "    # mind the indentation!\n",
    "    print(\"Current loop index: \", i)\n",
    "    print(\"Species: \", species[i])\n",
    "    print()\n",
    "\n",
    "# the following code is outside the for loop, so we deindent it:\n",
    "print(\"We exited the for loop :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the actual plotting now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    # extract the samples of class i\n",
    "    species_df = iris_df[ iris_df['species'] == i ]\n",
    "    # plot petal (y axis) vs sepal (x axis) length\n",
    "    plt.scatter(        \n",
    "        species_df['sepal length (cm)'],        \n",
    "        species_df['petal length (cm)'],\n",
    "        color=colours[i],        \n",
    "        alpha=0.5, # point transparency to better visualize overlaps\n",
    "        label=species[i]   \n",
    "    )\n",
    "\n",
    "# add axis labels, title and legend\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('petal length (cm)')\n",
    "plt.title('Iris dataset: petal length vs sepal length')\n",
    "plt.legend(loc='lower right')\n",
    "# finally, display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should plot all the possible combinations to get an idea of feature relationships.\n",
    "\n",
    "As we will see, there are multiple ways to accomplish this task. For now, we go the hard way and plot some combinations by hand. \n",
    "\n",
    "Here's sepal width vs sepal length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):    \n",
    "    species_df = iris_df[iris_df['species'] == i]    \n",
    "    plt.scatter(        \n",
    "        species_df['sepal length (cm)'],        \n",
    "        species_df['sepal width (cm)'],\n",
    "        color=colours[i],        \n",
    "        alpha=0.5,        \n",
    "        label=species[i]   \n",
    "    )\n",
    "\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "plt.title('Iris dataset: sepal width vs sepal length')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What can you infer about the relationship between these features and the target variable?_\n",
    "\n",
    "_Try plotting some other combinations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### space for practicing...\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more convenient way to see all the combinations is to do a **scatterplot matrix**.\n",
    "\n",
    "For example, we can achieve this through the plotting capabilities of the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import required stuff\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib.colors import ListedColormap\n",
    "# here we manually define a colormap (a list of colors) to color the species\n",
    "cmap_rob = ListedColormap(['#FF0000','#FFA500','#0000FF'])\n",
    "\n",
    "# for convenience, let's save the data and the labels in two objects:\n",
    "# 1. we take the iris dataframe and drop the species column\n",
    "X = iris_df.drop(columns=\"species\")\n",
    "# 2. now we take just the species column\n",
    "y = iris_df[\"species\"]\n",
    "\n",
    "scatter_matrix(X, c=y, \n",
    "               figsize=[10,10], s=50, cmap=cmap_rob, diagonal='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What can we understand of our Iris dataset from this kind of plot?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just FYI, there is another option, using the `seaborn` library.\n",
    "\n",
    "[seaborn](http://seaborn.pydata.org/) is based on matplotlib and provides a high-level interface for plotting statistical graphics that are also _attractive_ as they use enhanced color palettes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/seaborn_gallery.jpg\" width=\"65%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# set some graphical options\n",
    "sns.set(style=\"ticks\")\n",
    "# draw the scatterplot matrix directly from the pandas dataframe\n",
    "sns.pairplot(iris_df, hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have the histograms on the diagonal as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris_df, hue=\"species\", diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted the actual species name instead of 0, 1, 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['species'] = iris.target_names[iris.target]\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris_df, hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris: unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go on with our data exploration. We now want to apply a PCA on the 4-dimensional Iris dataset and look at the variance that is explained by each of the principal components. First off, we save again the data and the labels into two distinct variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris = iris.data\n",
    "y_iris = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Two observations here:_ \n",
    "\n",
    "1. Using standard machine learning notation, we save the **data** (without the target variable) into an object named **X** and the **target** into an object named **y** (with suffixes to improve readability);\n",
    "2. Since we will be using scikit-learn, which works on Numpy arrays rather than Pandas dataframes, we start from the `iris.data` and `iris.target` objects, which are Numpy arrays already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot to visualize how the data looks like (back to matplotlib now): we'll plot just the first two variables (you can experiment with other ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_rob = ListedColormap(['#FF0000','#FFA500','#0000FF'])\n",
    "plt.scatter(X_iris[:,0], X_iris[:,1], c=y_iris, cmap=cmap_rob)\n",
    "plt.xlabel('Sepal Length', fontsize=16)\n",
    "plt.ylabel('Sepal Width', fontsize=16)\n",
    "plt.title('Actual labels', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` makes it easy to compute the principal components through its module `decomposition`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X_iris)\n",
    "print('Variance percent explained\\n', pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What can we infer from the explained variances?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reduce the dimensionality of the dataset by projecting it onto a 2-dimensional space, as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the PCA again, keeping only the first two components\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X_iris)\n",
    "\n",
    "# actually transform the Iris data (i.e., apply the PCA transformation obtained using the fit function)\n",
    "Z = pca.transform(X_iris)\n",
    "\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Z to a pandas DataFrame, adding column names\n",
    "df_2D = pd.DataFrame(Z,\n",
    "                     columns=['PC1', 'PC2'])\n",
    "# also add a species column\n",
    "df_2D['species'] = iris_df['species']\n",
    "df_2D.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can now easily plot the resulting transformation, coloring points according to the species column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, group in df_2D.groupby(['species']):\n",
    "    plt.plot(group.PC1, group.PC2, 'o', alpha=0.7, label=key)\n",
    "    \n",
    "plt.legend(loc=0, fontsize=12)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use UMAP now. First, we import the module and instantiate the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE: see how I `import` required modules as I need them. This is only because this is a tutorial and I want to gradually introduce new stuff: usually you should `import` all the modules at the beginning of your script!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to standardize the feature values (i.e., so to have zero mean and unit variance): this can be easily accomplished with a scikit-learn one-liner, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_iris = StandardScaler().fit_transform(X_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We let the reducer object learn the manifold and return the reduced representation of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.fit_transform(scaled_iris)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reduced the dimensionality to 2 features. Let's plot this representation of the data as we did with the PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_2D = pd.DataFrame(embedding,\n",
    "                     columns=['UMAP1', 'UMAP2'])\n",
    "# also add a species column\n",
    "df_2D['species'] = iris_df['species']\n",
    "df_2D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, group in df_2D.groupby(['species']):\n",
    "    plt.plot(group.UMAP1, group.UMAP2, 'o', alpha=0.7, label=key)\n",
    "    \n",
    "plt.legend(loc=0, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider again the first two columns of `iris`, sepal length and width, respectively, together with their labels (target). Here I'll extract them from the `iris` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris = iris.data[:, :2]\n",
    "y_iris = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Side note / exercise:_\n",
    "\n",
    "Remember that there are always multiple ways to get a desired results. For example, you may want to use your `iris_df` dataframe as starting point, converting it into a Numpy array. This can be done on any Pandas dataframe `df` by just calling the method `values`, as in `df.values`. Try getting `X_iris`, `y_iris` in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### space for practicing...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot to visualize how the data looks like (back to matplotlib now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_rob = ListedColormap(['#FF0000','#FFA500','#0000FF'])\n",
    "plt.scatter(X_iris[:,0], X_iris[:,1], c=y_iris, cmap=cmap_rob)\n",
    "plt.xlabel('Sepal Length', fontsize=16)\n",
    "plt.ylabel('Sepal Width', fontsize=16)\n",
    "plt.title('Actual labels', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required library, create a k-means **instance** and fit the model.\n",
    "\n",
    "_Note:_ in scikit-learn, to use a model you have to first create it and assign it to a variable. This variable is called an  \"instance\" of the model, using object-oriented programming notation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=3, random_state=42)\n",
    "km.fit(X_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Note 1:_ `km` is now a **fitted model** object, i.e., it has several **attributes** accessible using the syntax `km` + dot (.) + attribute. See the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) for the list of all available attributes for KMeans objects.\n",
    "\n",
    "* _Note 2:_ notice how I specified a random seed. This is always needed when doing computations with random numbers (e.g. initializations, random partitioning, etc.). More on this later on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important attribute we are interested in right now is the `labels_` (mind the trailing underscore), which contains the cluster predictions. Save them into a new variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = km.labels_\n",
    "new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Important!_ The labels found by KMeans may be in a different order with respect to the original labels: for example, the KMeans label 1 may not be related to the original label 1. This is because KMeans finds clusters in an unsupervised way and labels them in a way determined by the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually check how the clustering results compare to the original data partitioning into species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_iris[:,0], X_iris[:,1], c=new_labels, cmap=cmap_rob, alpha=0.5)\n",
    "plt.xlabel('Sepal Length', fontsize=16)\n",
    "plt.ylabel('Sepal Width', fontsize=16)\n",
    "plt.title('Predicted labels', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Compare this plot with the previous one. What can you say about the predictions?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot in the same figure the data with actual labels and the predicted clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define step size for the meshgrid\n",
    "h = .02 \n",
    "# create a color map\n",
    "cmap_rob = ListedColormap(['#FF0000','#FFA500','#0000FF'])\n",
    "\n",
    "# assign a color to each point in the mesh [x_min, m_max]x[y_min, y_max] + something\n",
    "x_min, x_max = X_iris[:,0].min() - 1, X_iris[:,0].max() + 1\n",
    "y_min, y_max = X_iris[:,1].min() - 1, X_iris[:,1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), \n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = km.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.get_cmap(\"Paired\"), alpha = 0.07)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_iris[:, 0], X_iris[:, 1], c=y_iris, cmap=cmap_rob)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xlabel('Sepal Length', fontsize=16)\n",
    "plt.ylabel('Sepal Width', fontsize=16)\n",
    "plt.title(\"Iris kMeans (k = 3)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose now the petal length/width pair of features. Predict the clusters using a KMeans. Plot the features and the predicted clustes on a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "X_iris = iris.data[:, 2:]\n",
    "# redefine the target variable, just in case\n",
    "y_iris = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit a KMeans model on data, get the predicted cluster labels\n",
    "km = KMeans(n_clusters = 3, random_state=42)\n",
    "km.fit(X_iris)\n",
    "new_labels = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a color to each point in the mesh [x_min, m_max]x[y_min, y_max] + something\n",
    "x_min, x_max = X_iris[:,0].min() - 1, X_iris[:,0].max() + 1\n",
    "y_min, y_max = X_iris[:,1].min() - 1, X_iris[:,1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), \n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = km.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.get_cmap(\"Paired\"), alpha = 0.07)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_iris[:, 0], X_iris[:, 1], c=y_iris, cmap=cmap_rob)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xlabel('Petal Length', fontsize=16)\n",
    "plt.ylabel('Petal Width', fontsize=16)\n",
    "plt.title(\"Iris kMeans (k = 3)\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris: supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to fit a kNN model on the Iris dataset restricted to the sepal length/width feature pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tip: although we already did this earlier, it is good practice to redefine the variables, \n",
    "# just in case something happened in-between...\n",
    "X_sepal = iris.data[:, :2]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create k-NN instance (with default parameters) and fit the model. Note that default parameters imply the number of neighbors set to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(X_sepal, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know what the default parameters are, type the function name preceded or followed by ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors.KNeighborsClassifier??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to plot the decision boundaries. In order to do this we need to make a <i>meshgrid</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define step size for the meshgrid\n",
    "h = .02 \n",
    "# create a color map\n",
    "cmap_rob = ListedColormap(['#FF0000','#FFA500','#0000FF'])\n",
    "\n",
    "# assign a color to each point in the mesh [x_min, m_max]x[y_min, y_max] + something\n",
    "x_min, x_max = X_sepal[:,0].min() - 1, X_sepal[:,0].max() + 1\n",
    "y_min, y_max = X_sepal[:,1].min() - 1, X_sepal[:,1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), \n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_rob, alpha = 0.07)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_sepal[:, 0], X_sepal[:, 1], c=y, cmap=cmap_rob)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xlabel('Sepal Length', fontsize=16)\n",
    "plt.ylabel('Sepal Width', fontsize=16)\n",
    "plt.title(\"Iris k-NN (k = 5)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I want to do this again using as features petal width and length since previous plots suggest that these features are better off at separating the data. So I fit the model again using petal data and plot decision boundaries again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_petal = iris.data[:, 2:]\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(X_petal, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## then assign a color to each point in the mesh [x_min, m_max]x[y_min, y_max]\n",
    "x_min, x_max = X_petal[:,0].min() - 1, X_petal[:,0].max() + 1\n",
    "y_min, y_max = X_petal[:,1].min() - 1, X_petal[:,1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), \n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_rob, alpha = 0.07)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_petal[:, 0], X_petal[:, 1], c=y, cmap=cmap_rob)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xlabel('Petal Length', fontsize=16)\n",
    "plt.ylabel('Petal Width', fontsize=16)\n",
    "plt.title(\"Iris k-NN (k = 5)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?\n",
    "\n",
    "* Real-world data set\n",
    "* Training and test\n",
    "* Model performance\n",
    "* Cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "practical_neuroblastoma_partI_v0.2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
